# Bank Customer Churn Prediction üè¶

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-success.svg)]()

Modelo predictivo de Machine Learning para identificar clientes bancarios con alto riesgo de abandono, permitiendo implementar estrategias de retenci√≥n proactivas y basadas en datos.

---

## üìä Descripci√≥n del Proyecto

Este proyecto desarrolla un sistema integral de predicci√≥n de churn bancario utilizando t√©cnicas avanzadas de aprendizaje autom√°tico. El modelo analiza caracter√≠sticas demogr√°ficas, comportamiento financiero y patrones de uso para identificar clientes con alta probabilidad de abandonar el banco.

### üéØ Objetivo del Negocio

Reducir la tasa de abandono de clientes mediante:
- Identificaci√≥n temprana de clientes en riesgo
- Segmentaci√≥n inteligente para estrategias de retenci√≥n personalizadas
- Optimizaci√≥n del ROI en campa√±as de marketing
- Mejora en la experiencia del cliente

### üìà Caracter√≠sticas del Dataset

- **Tama√±o**: 10,000 registros de clientes bancarios
- **Objetivo**: Clasificaci√≥n binaria (Churn: 1 = Abandon√≥, 0 = Se qued√≥)
- **Caracter√≠sticas**: 14 variables predictoras
- **Balanceo**: Dataset desbalanceado (~20% churn rate)

### üîë Variables Predictoras

| Variable | Descripci√≥n | Tipo |
|----------|-------------|------|
| **CreditScore** | Puntuaci√≥n crediticia del cliente | Num√©rica (300-850) |
| **Geography** | Pa√≠s de residencia | Categ√≥rica (Francia, Espa√±a, Alemania) |
| **Gender** | G√©nero del cliente | Categ√≥rica (Masculino, Femenino) |
| **Age** | Edad del cliente | Num√©rica (18-92) |
| **Tenure** | A√±os como cliente del banco | Num√©rica (0-10) |
| **Balance** | Saldo en cuenta | Num√©rica (0-250,000+) |
| **NumOfProducts** | N√∫mero de productos bancarios | Num√©rica (1-4) |
| **HasCrCard** | Tiene tarjeta de cr√©dito | Binaria (0/1) |
| **IsActiveMember** | Cliente activo | Binaria (0/1) |
| **EstimatedSalary** | Salario estimado | Num√©rica (11-200,000) |

---

## üéØ Resultados del Modelo

### M√©tricas de Performance

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **Accuracy** | 86% | Precisi√≥n general del modelo |
| **Precision** | 78% | De los predichos como churn, 78% son correctos |
| **Recall** | 72% | Detecta 72% de los clientes que abandonar√°n |
| **F1-Score** | 75% | Balance entre precisi√≥n y recall |
| **ROC-AUC** | 0.85 | Excelente capacidad discriminativa |

### üìä Matriz de Confusi√≥n

```
                 Predicho: No Churn    Predicho: Churn
Real: No Churn         1,580                 120
Real: Churn              140                 360
```

### üí° Interpretaci√≥n de Negocio

- **Alta Precision (78%)**: Reduce costos al evitar falsas alarmas en campa√±as de retenci√≥n
- **Buen Recall (72%)**: Captura la mayor√≠a de clientes en riesgo, maximizando oportunidades de retenci√≥n
- **ROC-AUC 0.85**: El modelo distingue muy bien entre clientes que se quedar√°n vs. abandonar√°n
- **Impacto Estimado**: Potencial reducci√≥n del 50% en tasa de churn al intervenir proactivamente

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Lenguaje y Entorno
```python
Python 3.10+
Jupyter Notebook / JupyterLab
```

### An√°lisis y Manipulaci√≥n de Datos
```python
pandas==2.0.3          # Manipulaci√≥n de DataFrames
numpy==1.24.3          # Operaciones num√©ricas
```

### Machine Learning
```python
scikit-learn==1.3.0    # Algoritmos de ML y m√©tricas
imbalanced-learn==0.11.0  # SMOTE para balanceo de clases
```

### Visualizaci√≥n
```python
matplotlib==3.7.2      # Gr√°ficos base
seaborn==0.12.2        # Visualizaciones estad√≠sticas
plotly==5.16.1         # Gr√°ficos interactivos (opcional)
```

### Herramientas Adicionales
```python
joblib==1.3.2          # Serializaci√≥n de modelos
shap==0.42.1           # Interpretabilidad del modelo (futuro)
```

---

## üìÅ Estructura del Proyecto

```
bank-churn-prediction/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales sin modificar
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Churn_Modelling.csv       # Dataset principal
‚îÇ   ‚îî‚îÄ‚îÄ processed/                    # Datos procesados y limpios
‚îÇ       ‚îú‚îÄ‚îÄ train_processed.csv       # Conjunto de entrenamiento
‚îÇ       ‚îî‚îÄ‚îÄ test_processed.csv        # Conjunto de prueba
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_analysis.ipynb      # EDA completo
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb       # Transformaci√≥n de features
‚îÇ   ‚îî‚îÄ‚îÄ 03_modeling.ipynb                  # Entrenamiento y evaluaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ src/                              # Scripts Python modulares (futuro)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py         # Funciones de limpieza
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py        # Transformaci√≥n de features
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py             # Entrenamiento de modelos
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation.py           # M√©tricas y evaluaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ models/                           # Modelos entrenados serializados
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_model.pkl       # Modelo final
‚îÇ   ‚îî‚îÄ‚îÄ model_metadata.json           # Hiperpar√°metros y m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                      # Gr√°ficos y visualizaciones
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ correlation_heatmap.png
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation_report.pdf   # Reporte t√©cnico completo
‚îÇ
‚îú‚îÄ‚îÄ tests/                            # Tests unitarios (futuro)
‚îÇ   ‚îî‚îÄ‚îÄ test_preprocessing.py
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                        # Archivos a ignorar en Git
‚îú‚îÄ‚îÄ LICENSE                           # Licencia MIT
‚îú‚îÄ‚îÄ README.md                         # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                  # Dependencias del proyecto
‚îî‚îÄ‚îÄ setup.py                          # Instalaci√≥n del paquete (futuro)
```

---

## üöÄ Instalaci√≥n y Uso

### Prerrequisitos

- Python 3.10 o superior
- pip (gestor de paquetes)
- Git

### Instalaci√≥n Paso a Paso

1. **Clonar el repositorio**
```bash
git clone https://github.com/nnvelez95/bank-churn-prediction.git
cd bank-churn-prediction
```

2. **Crear entorno virtual**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

4. **Verificar instalaci√≥n**
```bash
python -c "import pandas, sklearn, seaborn; print('‚úÖ Todo instalado correctamente')"
```

### üéì Uso del Proyecto

#### Opci√≥n 1: Ejecutar Notebooks (Recomendado para exploraci√≥n)

```bash
jupyter notebook
```

Abrir y ejecutar en orden:
1. `notebooks/01_exploratory_analysis.ipynb` - EDA y visualizaciones
2. `notebooks/02_feature_engineering.ipynb` - Preparaci√≥n de datos
3. `notebooks/03_modeling.ipynb` - Entrenamiento y evaluaci√≥n

#### Opci√≥n 2: Scripts Python (Futuro - para producci√≥n)

```bash
# Preprocesar datos
python src/data_preprocessing.py --input data/raw/Churn_Modelling.csv --output data/processed/

# Entrenar modelo
python src/model_training.py --data data/processed/ --output models/

# Evaluar modelo
python src/model_evaluation.py --model models/random_forest_model.pkl --test-data data/processed/test_processed.csv
```

---

## üìà Metodolog√≠a y Pipeline

### 1Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA)

**Objetivos:**
- Comprender distribuciones de variables
- Identificar patrones y correlaciones
- Detectar outliers y valores faltantes
- An√°lisis de tasa de churn por segmentos

**T√©cnicas aplicadas:**
- Estad√≠sticas descriptivas
- An√°lisis univariado y bivariado
- Matrices de correlaci√≥n
- Visualizaciones avanzadas (boxplots, histogramas, heatmaps)

**Hallazgos clave:**
- Balance cero indica alta probabilidad de churn
- Clientes con 1 solo producto son m√°s propensos a abandonar
- Edad 40-50 a√±os muestra mayor tasa de abandono
- Miembros inactivos tienen 3x m√°s riesgo

### 2Ô∏è‚É£ Ingenier√≠a de Caracter√≠sticas

**Transformaciones realizadas:**
```python
# Variables categ√≥ricas
- Label Encoding: Geography, Gender
- One-Hot Encoding: Alternativa evaluada

# Variables num√©ricas
- StandardScaler: Age, CreditScore, Balance, EstimatedSalary
- MinMaxScaler: Alternativa para modelos basados en distancias

# Features derivadas (futuro)
- Balance_per_Product = Balance / NumOfProducts
- Tenure_Age_Ratio = Tenure / Age
- High_Value_Customer = (Balance > 100000) & (NumOfProducts >= 2)
```

**Tratamiento de desbalanceo:**
- SMOTE (Synthetic Minority Over-sampling Technique)
- Random Under-sampling de clase mayoritaria
- Class weights en modelos

### 3Ô∏è‚É£ Modelado y Selecci√≥n de Algoritmos

**Modelos evaluados:**

| Modelo | ROC-AUC | Accuracy | Recall | Tiempo |
|--------|---------|----------|--------|--------|
| Logistic Regression | 0.78 | 81% | 65% | < 1s |
| Random Forest ‚≠ê | 0.85 | 86% | 72% | ~5s |
| XGBoost | 0.84 | 85% | 71% | ~3s |
| SVM (RBF) | 0.80 | 83% | 68% | ~10s |
| Neural Network | 0.82 | 84% | 69% | ~15s |

**Modelo seleccionado: Random Forest**
- Mejor balance entre m√©tricas
- Robusto ante outliers
- Permite interpretabilidad (feature importance)
- No requiere escalado estricto

**Hiperpar√°metros optimizados:**
```python
{
    'n_estimators': 200,
    'max_depth': 15,
    'min_samples_split': 10,
    'min_samples_leaf': 4,
    'max_features': 'sqrt',
    'class_weight': 'balanced'
}
```

### 4Ô∏è‚É£ Validaci√≥n y Evaluaci√≥n

**Estrategia de validaci√≥n:**
- Train/Test split: 80/20
- Cross-validation: 5-fold
- Stratified sampling (mantiene proporci√≥n de churn)

**M√©tricas de negocio:**
```python
# Costo de falso negativo (no detectar churn)
FN_cost = $500  # Costo de perder un cliente

# Costo de falso positivo (campa√±a innecesaria)
FP_cost = $50   # Costo de campa√±a de retenci√≥n

# ROI esperado del modelo
Expected_savings = (True_Positives * $500) - (False_Positives * $50)
```

---

## üí° Insights de Negocio

### üìä Top 5 Variables M√°s Importantes

1. **Age (28%)** - Clientes 40-50 a√±os, mayor riesgo
2. **NumOfProducts (22%)** - 1 producto = alto riesgo, 3-4 = bajo riesgo
3. **IsActiveMember (18%)** - Inactividad multiplica riesgo x3
4. **Balance (15%)** - Balance extremo (muy bajo/alto) = riesgo
5. **Geography (12%)** - Alemania muestra mayor tasa de churn

### üéØ Recomendaciones Estrat√©gicas

#### Para Marketing y Retenci√≥n
1. **Programa de activaci√≥n de clientes inactivos**
   - Email marketing personalizado
   - Incentivos de uso (cashback, descuentos)
   - Push notifications en app m√≥vil

2. **Cross-selling inteligente**
   - Ofrecer productos complementarios a clientes con 1-2 productos
   - Bundles personalizados seg√∫n perfil

3. **Segmentaci√≥n geogr√°fica**
   - Estrategias diferenciadas por pa√≠s
   - Alemania requiere atenci√≥n especial

#### Para Producto
1. **Mejorar engagement de clientes 40-50 a√±os**
   - UX adaptada a este segmento
   - Productos espec√≠ficos (planificaci√≥n de retiro)

2. **Alertas para clientes de balance extremo**
   - Balance = 0: Riesgo de inactividad
   - Balance muy alto sin productos: Oportunidad de inversi√≥n

### üìâ Estimaci√≥n de Impacto

**Escenario actual (sin modelo):**
- Tasa de churn: 20%
- Clientes perdidos/a√±o: 2,000
- Costo estimado: $1,000,000

**Escenario con modelo (intervenci√≥n proactiva):**
- Clientes detectados en riesgo: 1,440 (72% recall)
- Tasa de retenci√≥n con campa√±a: 40%
- Clientes retenidos: 576
- **Ahorro estimado: $288,000/a√±o**
- **ROI del modelo: 480%** (asumiendo costo campa√±a $60,000)

---

## üîÆ Roadmap y Futuras Features

### üöÄ Fase 1: Mejoras en el Modelo (Q1 2026)

#### Machine Learning Avanzado
- [ ] **Ensemble Stacking**: Combinar Random Forest + XGBoost + Neural Network
- [ ] **Hyperparameter Tuning con Optuna**: Optimizaci√≥n bayesiana avanzada
- [ ] **Calibraci√≥n de probabilidades**: Platt scaling para mejores probabilidades
- [ ] **Interpretabilidad con SHAP**: Explicar predicciones individuales
- [ ] **Feature Selection avanzado**: RFE (Recursive Feature Elimination)

#### Feature Engineering v2.0
- [ ] **Variables de interacci√≥n**: Age_x_NumOfProducts, Balance_x_Tenure
- [ ] **Binning inteligente**: Discretizaci√≥n de Age, Balance con √≥ptimos puntos de corte
- [ ] **Polynomial Features**: Relaciones no lineales entre variables
- [ ] **Time-based features**: Si se incorporan datos temporales
- [ ] **Clustering de clientes**: KMeans para segmentaci√≥n, usar cluster como feature

### üìä Fase 2: Productizaci√≥n (Q2 2026)

#### API REST para Predicciones
```python
# Endpoint de predicci√≥n en tiempo real
POST /api/v1/predict
{
  "customer_id": 12345,
  "age": 42,
  "balance": 85000,
  ...
}

Response:
{
  "churn_probability": 0.73,
  "risk_level": "HIGH",
  "top_factors": ["age", "num_products", "is_active"],
  "recommended_action": "retention_campaign_tier_1"
}
```

**Stack tecnol√≥gico:**
- [ ] FastAPI para endpoints
- [ ] Docker para containerizaci√≥n
- [ ] Redis para caching de predicciones
- [ ] PostgreSQL para logging de predicciones
- [ ] Celery para batch predictions

#### CI/CD y MLOps
- [ ] **GitHub Actions**: Testing autom√°tico en cada push
- [ ] **Model versioning con MLflow**: Tracking de experimentos
- [ ] **Model monitoring**: Detectar data drift y model decay
- [ ] **A/B testing framework**: Comparar modelos en producci√≥n
- [ ] **Automated retraining**: Pipeline mensual de reentrenamiento

### üì± Fase 3: Interfaces de Usuario (Q3 2026)

#### Dashboard Interactivo con Streamlit
```python
# Caracter√≠sticas del dashboard:
- üìä M√©tricas en tiempo real (churn rate, predicciones diarias)
- üîç B√∫squeda de cliente individual
- üìà Gr√°ficos interactivos (filtros por segmento)
- üéØ Segmentaci√≥n din√°mica de clientes
- üì• Exportaci√≥n de listas de clientes en riesgo
- üîî Alertas configurables
```

- [ ] Deploy en Streamlit Cloud / Heroku
- [ ] Autenticaci√≥n de usuarios (JWT)
- [ ] Roles (Admin, Marketing, Analyst)

#### Integraci√≥n con CRM
- [ ] Webhook a Salesforce/HubSpot cuando se detecta alto riesgo
- [ ] Enriquecimiento autom√°tico de perfiles de cliente
- [ ] Triggers para campa√±as de email marketing (Mailchimp/SendGrid)

### üß† Fase 4: Deep Learning y Series Temporales (Q4 2026)

#### Modelos Secuenciales
- [ ] **LSTM/GRU**: Predecir churn basado en secuencias de transacciones
- [ ] **Transformers**: Atenci√≥n temporal en comportamiento de cliente
- [ ] **Survival Analysis**: Cox Proportional Hazards para tiempo hasta churn

#### Nuevas Fuentes de Datos
```python
# Datos adicionales a incorporar:
- Historial de transacciones (monto, frecuencia, tipo)
- Interacciones con servicio al cliente (tickets, llamadas)
- Uso de canales digitales (app m√≥vil, web banking)
- Respuesta a campa√±as de marketing previas
- Datos de redes sociales (sentiment analysis)
```

### ü§ñ Fase 5: Inteligencia Artificial Generativa (2027)

#### Personalizaci√≥n con LLMs
- [ ] **Generaci√≥n autom√°tica de emails de retenci√≥n**: Personalizados con GPT-4
- [ ] **Chatbot predictivo**: "Hemos notado que podr√≠as estar interesado en..."
- [ ] **An√°lisis de sentimiento**: Procesar feedback de clientes con NLP
- [ ] **Recomendaciones explicables**: "Te sugerimos X porque..."

#### AutoML y No-Code ML
- [ ] **AutoML pipeline**: H2O.ai o AutoKeras para b√∫squeda autom√°tica de modelos
- [ ] **Low-code interface**: Para que equipos de negocio ejecuten predicciones

### üìä Fase 6: Business Intelligence Avanzado

#### Simuladores y Optimizadores
- [ ] **What-if Analysis**: "¬øQu√© pasar√≠a si aumentamos el balance m√≠nimo?"
- [ ] **Optimizador de campa√±as**: Calcular ROI √≥ptimo de estrategias de retenci√≥n
- [ ] **Segmentaci√≥n autom√°tica**: RFM + Churn score para marketing

#### Reporting Automatizado
- [ ] PDF reports semanales para stakeholders
- [ ] Slack/Teams bot con m√©tricas diarias
- [ ] Power BI/Tableau integration

---

## üß™ Testing y Calidad

### Tests Implementados (Futuro)
```bash
# Ejecutar tests
pytest tests/ -v --cov=src

# Tests de integraci√≥n
pytest tests/integration/ -v

# Tests de rendimiento
pytest tests/performance/ -v --benchmark-only
```

### Cobertura de Testing
- [ ] Unit tests para preprocessing (>90% coverage)
- [ ] Integration tests para pipeline completo
- [ ] Performance tests (latencia < 100ms por predicci√≥n)
- [ ] Data validation tests (schema, ranges)

---

## üìö Recursos y Referencias

### Documentaci√≥n T√©cnica
- [Scikit-learn: RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Imbalanced-learn: SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)
- [SHAP for Model Interpretability](https://shap.readthedocs.io/)

### Papers Acad√©micos
- *Handling Imbalanced Datasets* - He & Garcia (2009)
- *Random Forests* - Breiman (2001)
- *Customer Churn Prediction in Banking* - Jahromi et al. (2022)

### Datasets Similares
- [Kaggle: Bank Customer Churn](https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction)
- [UCI ML Repository: Bank Marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing)

---

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Sigue estos pasos:

### Proceso de Contribuci√≥n

1. **Fork el proyecto**
2. **Crea una rama para tu feature**
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit tus cambios**
   ```bash
   git commit -m 'Add: Nueva funcionalidad X'
   ```
4. **Push a la rama**
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Abre un Pull Request**

### Est√°ndares de C√≥digo
- Seguir PEP 8 (Python Style Guide)
- Documentar funciones con docstrings
- Incluir tests para nuevas features
- Actualizar README si es necesario

### Issues y Bugs
Si encuentras un bug o tienes una sugerencia:
1. Revisa los [issues existentes](https://github.com/nnvelez95/bank-churn-prediction/issues)
2. Si no existe, crea uno nuevo con:
   - Descripci√≥n clara del problema/sugerencia
   - Pasos para reproducir (si es bug)
   - Screenshots (si aplica)

---

## üìù Licencia

Este proyecto est√° bajo la **Licencia MIT**. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

```
MIT License

Copyright (c) 2026 Norberto Velez

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## üë§ Autor

**Norberto Velez**

Data Scientist | Machine Learning Engineer

- üîó LinkedIn: [linkedin.com/in/norberto-velez-672916172](https://linkedin.com/in/norberto-velez-672916172)
- üìß Email: [nnvelez95@gmail.com](mailto:nnvelez95@gmail.com)
- üíº GitHub: [@nnvelez95](https://github.com/nnvelez95)
- üåê Portfolio: [En construcci√≥n](#)

### Otros Proyectos
- Pr√≥ximamente m√°s proyectos de Data Science y ML

---

## üìß Contacto y Soporte

¬øTienes preguntas? ¬øNecesitas ayuda con el proyecto?

- **Email**: nnvelez95@gmail.com
- **LinkedIn**: [Env√≠ame un mensaje](https://linkedin.com/in/norberto-velez-672916172)
- **GitHub Issues**: [Abrir un issue](https://github.com/nnvelez95/bank-churn-prediction/issues)

---

## üôè Agradecimientos

- Dataset original de [Kaggle](https://www.kaggle.com/)
- Comunidad de Scikit-learn por excelente documentaci√≥n
- Stack Overflow por resolver dudas puntuales
- A todos los que contribuyan a este proyecto

---

## üìä Estad√≠sticas del Proyecto

![GitHub stars](https://img.shields.io/github/stars/nnvelez95/bank-churn-prediction?style=social)
![GitHub forks](https://img.shields.io/github/forks/nnvelez95/bank-churn-prediction?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/nnvelez95/bank-churn-prediction?style=social)
![GitHub last commit](https://img.shields.io/github/last-commit/nnvelez95/bank-churn-prediction)
![GitHub code size](https://img.shields.io/github/languages/code-size/nnvelez95/bank-churn-prediction)

---

<div align="center">

### ‚≠ê Si este proyecto te result√≥ √∫til, considera darle una estrella

**Desarrollado con ‚ù§Ô∏è por Norberto Velez**

[üîù Volver arriba](#bank-customer-churn-prediction-)

</div>
